# Some popular notebooks' collection for ML experiments
## Research
| Name | Description | Authors | Links | Open in TIR |
|------|-------------|:--------|:------|:-----------:|
| OWL-ViT | Simple Open-Vocabulary Object Detection with Vision Transformers | <ul><li>[Matthias Minderer](http://matthias.minderer.net/)</li><details><summary>others</summary><li>[Alexey Gritsenko](https://github.com/AlexeyG)</li> <li>[Austin Stone](https://github.com/AustinCStone)</li> <li>[Maxim Neumann](https://github.com/maximneumann)</li> <li>[Dirk Weissenborn](https://github.com/dirkweissenborn)</li> <li>[Alexey Dosovitskiy](https://scholar.google.com/citations?user=FXNJRDoAAAAJ)</li> <li>[Aravindh Mahendran](https://github.com/aravindhm)</li> <li>[Anurag Arnab](https://github.com/anuragarnab)</li> <li>[Mostafa Dehghani](https://mostafadehghani.com/)</li> <li>[Zhuoran Shen](https://cmsflash.github.io/)</li> <li>[Xiao Wang](https://scholar.google.com/citations?user=ukyXqzMAAAAJ)</li> <li>[Xiaohua Zhai](https://github.com/xiaohuazhai)</li> <li>[Thomas Kipf](https://tkipf.github.io/)</li> <li>[Neil Houlsby](https://neilhoulsby.github.io/)</li></ul></details> | [![](https://img.shields.io/github/stars/google-research/scenic?style=social)](https://github.com/google-research/scenic/tree/main/scenic/projects/owl_vit) <ul><li>[<img src="images/arxiv.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/2205.06230)</li><li>[<img src="images/huggingface.svg" alt="huggingface" height=20/>](https://huggingface.co/docs/transformers/model_doc/owlvit)</li></ul> | [<img src="images/open-in-tir.png" alt="Open In TIR" width=200/>](https://gpu-notebooks.e2enetworks.com/github/tire2e/notebooks/blob/main/notebooks/zeroshot_object_detection_with_owlvit.ipynb/) |
| DeOldify (video) | Colorize your own videos! | [Jason Antic](https://github.com/jantic) | <ul><li>[<img src="images/arxiv.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1805.08318), [<img src="images/arxiv.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1706.08500)</li><li>[<img src="images/medium.svg" alt="medium" height=20/>](https://medium.com/element-ai-research-lab/stabilizing-neural-style-transfer-for-video-62675e203e42)</li><li>[model](https://data.deepai.org/deoldify/ColorizeVideo_gen.pth)</li><li>[<img src="images/reddit.svg" alt="reddit" height=20/>](https://www.reddit.com/r/Nickelodeons/), [<img src="images/reddit.svg" alt="reddit" height=20/>](https://www.reddit.com/r/silentmoviegifs/)</li><li>[<img src="images/youtube.svg" alt="youtube" height=20/>](http://www.youtube.com/watch?v=l3UXXid04Ys), [<img src="images/youtube.svg" alt="youtube" height=20/>](http://www.youtube.com/watch?v=EXn-n2iqEjI)</li></ul> | [<img src="images/open-in-tir.png" alt="Open In TIR" width=200/>](https://gpu-notebooks.e2enetworks.com/github/tire2e/notebooks/blob/main/notebooks/VideoColorizerColab.ipynb/) |
| DeOldify (photo) | Colorize your own photos! | <ul><li>[Jason Antic](https://github.com/jantic)</li><details><summary>others</summary><li>[Matt Robinson](https://github.com/mc-robinson)</li> <li>[Mar√≠a Benavente](https://github.com/mariabg)</li></ul></details> | <ul><li>[<img src="images/arxiv.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1805.08318), [<img src="images/arxiv.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1706.08500)</li><li>[model](https://data.deepai.org/deoldify/ColorizeArtistic_gen.pth)</li><li>[<img src="images/reddit.svg" alt="reddit" height=20/>](https://www.reddit.com/r/TheWayWeWere/)</li></ul> | [<img src="images/open-in-tir.png" alt="Open In TIR" width=200/>](https://gpu-notebooks.e2enetworks.com/github/tire2e/notebooks/blob/main/notebooks/ImageColorizerColab.ipynb/) |
## Tutorials
| Name | Description | Authors | Links | Open in TIR |
|------|-------------|:--------|:------|:-----------:|
| Pix2Pix | This notebook demonstrates image to image translation using conditional GAN's | [Billy Lamberta](https://github.com/lamberta) | <ul><li>[<img src="images/arxiv.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1611.07004)</li><li>[data](https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/)</li></ul> | [<img src="images/open-in-tir.png" alt="Open In TIR" width=200/>](https://gpu-notebooks.e2enetworks.com/github/tire2e/notebooks/blob/main/notebooks/pix2pix.ipynb/) |
| DCGAN | This tutorial demonstrates how to generate images of handwritten digits using a Deep Convolutional Generative Adversarial Network | [Billy Lamberta](https://github.com/lamberta) | <ul><li>[<img src="images/arxiv.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1511.06434), [<img src="images/arxiv.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1701.00160)</li><li>[<img src="images/kaggle.svg" alt="kaggle" height=20/>](https://www.kaggle.com/jessicali9530/celeba-dataset)</li></ul> | [<img src="images/open-in-tir.png" alt="Open In TIR" width=200/>](https://gpu-notebooks.e2enetworks.com/github/tire2e/notebooks/blob/main/notebooks/dcgan.ipynb/) |
| Classification of chest vs. adominal X-rays | The goal of this tutorial is to build a deep learning classifier to accurately differentiate between chest and abdominal X-rays | [tmoneyx01](https://github.com/tmoneyx01) | [![](https://img.shields.io/github/stars/mdai/mdai-client-py?style=social)](https://github.com/mdai/mdai-client-py) <ul><li>[annotator](https://public.md.ai/annotator/project/PVq9raBJ)</li><li>[<img src="images/docs.svg" alt="docs" height=20/>](https://docs.md.ai/)</li></ul> | [<img src="images/open-in-tir.png" alt="Open In TIR" width=200/>](https://gpu-notebooks.e2enetworks.com/github/tire2e/notebooks/blob/main/notebooks/medical-imaging-lessons-mdai/lesson1-xray-images-classification.ipynb/) |
| Lung X-Rays Semantic Segmentation | This lesson applies a U-Net for Semantic Segmentation of the lung fields on chest x-rays | [tmoneyx01](https://github.com/tmoneyx01) | [![](https://img.shields.io/github/stars/mdai/mdai-client-py?style=social)](https://github.com/mdai/mdai-client-py) <ul><li>[annotator](https://public.md.ai/annotator/project/aGq4k6NW)</li><li>[<img src="images/arxiv.svg" alt="arxiv" height=20/>](https://arxiv.org/abs/1505.04597)</li><li>[data](https://ceb.nlm.nih.gov/repositories/tuberculosis-chest-x-ray-image-data-sets/)</li><li>[<img src="images/docs.svg" alt="docs" height=20/>](https://docs.md.ai/)</li></ul> | [<img src="images/open-in-tir.png" alt="Open In TIR" width=200/>](https://gpu-notebooks.e2enetworks.com/github/tire2e/notebooks/blob/main/notebooks/medical-imaging-lessons-mdai/lesson2-lung-xrays-segmentation.ipynb/) |
# Best of the best
| Top Authors | Top Repositories |
|---|---|
| <ul><li>[Jason Antic](https://github.com/jantic)</li> <li>[tmoneyx01](https://github.com/tmoneyx01)</li> <li>[Billy Lamberta](https://github.com/lamberta)</li></ul> | <ul><li>google-research/scenic [![](https://img.shields.io/github/stars/google-research/scenic?style=social)](https://github.com/google-research/scenic/tree/main/scenic/projects/owl_vit)</li> <li>mdai/mdai-client-py [![](https://img.shields.io/github/stars/mdai/mdai-client-py?style=social)](https://github.com/mdai/mdai-client-py)</li></ul> |
